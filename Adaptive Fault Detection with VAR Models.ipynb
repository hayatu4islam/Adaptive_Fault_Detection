{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7fb8991-26fd-485f-bdea-db4210cb86da",
   "metadata": {},
   "source": [
    "### Adaptive Fault Detection with VAR Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd88b48-45f7-4061-b2a1-796ccc1b4a7a",
   "metadata": {},
   "source": [
    "##### Import libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d6bf16cb-e4ad-433b-b766-cb8db2ba4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages and libraries\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "from statsmodels.tsa.api import VAR\n",
    "from os.path import exists\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignoe harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the plot size default\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (12, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a927d1-92a1-4fad-a170-98679fb7c154",
   "metadata": {},
   "source": [
    "### Defining methods or functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b3720217-1183-4f5b-8fdd-2d324345f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting multiple series\n",
    "def plot_multiple_series(actual, pred, attr):\n",
    "    for i in range(len(attr)):\n",
    "        title = \"Prediction of {}\".format(attr[i])\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Timestep\")\n",
    "        plt.ylabel(\"Values\")\n",
    "        plt.plot(actual.iloc[:,i], label=\"actual\")\n",
    "        plt.plot(pred.iloc[:,i], label=\"forecast\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Root mean squared error\n",
    "def root_mse(x, y):\n",
    "    if len(x) != len(y):\n",
    "        return \"Error: The two arguments must have the same length\"\n",
    "    mse = np.square(np.subtract(x, y)).mean()\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "# Plotting series\n",
    "def plot_series(series, attr):\n",
    "    for i in range(len(attr)):\n",
    "        title = \"Plot of \"+str(attr[i])\n",
    "        actual = series.iloc[:,i]\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Timestep\")\n",
    "        plt.ylabel(attr[i])\n",
    "        plt.plot(actual)\n",
    "        plt.show()\n",
    "\n",
    "# Normalisation of time series\n",
    "def normalise_timeseries(data):\n",
    "    # Calculate the mean and standard deviation for each feature\n",
    "    means = np.mean(data, axis=0)\n",
    "    stds = np.std(data, axis=0)\n",
    "    \n",
    "    # Normalise each feature using standard deviation\n",
    "    normalised_data = (data - means) / stds\n",
    "    return pd.DataFrame(normalised_data)\n",
    "\n",
    "\n",
    "# Denomalisation of time series\n",
    "def denormalise_timeseries(data, means, stds):\n",
    "    denormalised_data = (data * stds) + means\n",
    "    return pd.DataFrame(denormalised_data)\n",
    "\n",
    "\n",
    "# Augmented Dickey-Fuller Test\n",
    "def adf_test(series, title=''):\n",
    "    '''\n",
    "    Hypothesis Test for Stationarity\n",
    "    Pass in a time series and an optional title, return an ADF report\n",
    "    '''\n",
    "    print(f'Augmented Dickey-Fuller Test: {title}')\n",
    "    result = adfuller(series.dropna(),autolag='AIC')\n",
    "    labels = ['ADF test statistics','p-value','#lags','#observations'] # use help(adfuller) to understand why these labels are chosen\n",
    "    \n",
    "    outcome = pd.Series(result[0:4],index=labels)\n",
    "    \n",
    "    for key,val in result[4].items():\n",
    "        outcome[f'critical value ({key})'] = val\n",
    "        \n",
    "    print(outcome.to_string()) # this will not print the line 'dtype:float64'\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print('Strong evidence against the null hypothesis') # Ho is Data is not stationary, check help(adfuller)\n",
    "        print('Reject the null hypothesis')\n",
    "        print('Data is Stationary')\n",
    "    else:\n",
    "        print('Weak evidence against the Null hypothesis')\n",
    "        print('Fail to reject the null hypothesis')\n",
    "        print('Data has a unit root and is non stationary')\n",
    "\n",
    "\n",
    "# Loading expert models in a dictionary and count the number of expert models\n",
    "def load_expert_models(expert_path):\n",
    "    files = os.listdir(expert_path)\n",
    "    pickle_files = [file for file in files if file.endswith('.pkl')]\n",
    "    models = {}\n",
    "\n",
    "    for file in pickle_files:\n",
    "        full_path = os.path.join('expert_models', file)  # Create full path\n",
    "        try:        \n",
    "            with open(full_path, 'rb') as f:\n",
    "                loaded_expert = pickle.load(f)\n",
    "                models[file.split('.')[0]] = loaded_expert\n",
    "                # print(loaded_expert)\n",
    "        except FileNotFoundError:\n",
    "            print(\"File not found. Please check the file path.\")\n",
    "        except PermissionError:\n",
    "            print(\"Permission denied. You don't have the necessary permissions.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    \n",
    "    return models\n",
    "    \n",
    "def file_names_string(file_path):\n",
    "    files = os.listdir(file_path)\n",
    "    for file_name in files:\n",
    "        if not isinstance(file_name, str):\n",
    "            return False\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dcbefb-4aab-4d57-ae19-8ebb65d8f1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "84b5eea8-d94f-4446-9e66-414e85a65314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = os.listdir('expert_models')\n",
    "# pickle_files = [file for file in files if file.endswith('.pkl')]\n",
    "# print(f'There are {len(pickle_files)} files in the directory')\n",
    "# for file in pickle_files:\n",
    "#     full_path = os.path.join('expert_models', file)  # Create full path\n",
    "#     print(f\"Full path: {full_path}\")  # Print the full path\n",
    "#     print(\"---Loading model---\")\n",
    "#     try:        \n",
    "#         with open(full_path, 'rb') as f:\n",
    "#             loaded_expert = pickle.load(f)\n",
    "#             print(loaded_expert)\n",
    "#     except FileNotFoundError:\n",
    "#         print(\"File not found. Please check the file path.\")\n",
    "#     except PermissionError:\n",
    "#         print(\"Permission denied. You don't have the necessary permissions.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#     print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cd68cc39-fb57-41c3-92a9-4e1d6089fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = os.listdir('expert_models')\n",
    "# pickle_files = [file for file in files if file.endswith('.pkl')]\n",
    "# print(f'There are {len(pickle_files)} files in the directory')\n",
    "# for file in pickle_files:\n",
    "#     print(\"---Loading model---\")\n",
    "#     print(file)\n",
    "#     try:        \n",
    "#         with open(file, 'rb') as f:\n",
    "#             loaded_expert = pickle.load(f)\n",
    "#             print(loaded_expert)\n",
    "#     except FileNotFoundError:\n",
    "#         print(\"File not found. Please check the file path.\")\n",
    "#     except PermissionError:\n",
    "#         print(\"Permission denied. You don't have the necessary permissions.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37408e1c-6c4d-4d76-92a7-107d6a9b8885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d76c7d-830f-4f05-a729-306d34fe5020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8fb6ee-9791-437c-af94-553b84dc8335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "906ba73d-7a64-47b5-83c0-885b814b55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning variables\n",
    "# file = 'test_series_reduced.csv'\n",
    "file = 'stuckat1_training_reduced_new.csv'\n",
    "# file = 'valueflip_training_reduced_new.csv'\n",
    "# file = 'stuckat1_training_reduced.csv'\n",
    "experts_path = 'expert_models'\n",
    "df_raw = read_csv(file, header=0, index_col=0)\n",
    "attr = list(pd.read_csv(file).columns.values)[1:]\n",
    "series = df_raw.iloc[:40000,:]\n",
    "# plot_series(series, attr)\n",
    "nobs = 3000\n",
    "# steps = 15\n",
    "steps = 20\n",
    "begin = 2000\n",
    "finish = 2200\n",
    "normalised_data = normalise_timeseries(df_raw)\n",
    "testData = normalised_data.copy()\n",
    "train = testData.iloc[:-nobs]\n",
    "test = testData.iloc[-nobs:]\n",
    "# len(train), len(test)\n",
    "input1 = testData.iloc[begin:finish,:]\n",
    "# plot_series(input1, attr)\n",
    "prediction_error = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8ec906ac-c777-460e-bae0-96c6883702b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold prediction error value\n",
    "threshold = 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "44cb1b04-0f56-47e9-abb8-84a1ba5ee808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checker = file_names_string(expert_path)\n",
    "# print(checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8dd338af-bf6b-4075-9492-924feb7a1890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<statsmodels.tsa.vector_ar.var_model.VARResultsWrapper object at 0x0000022B850C8A90>\n"
     ]
    }
   ],
   "source": [
    "# Load the expert models\n",
    "my_experts = load_expert_models(experts_path)\n",
    "# print(my_experts)\n",
    "print(my_experts['var_ctrl_stuckat0_perm_reduced'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "88887aac-0402-463e-851a-b3b700807331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = 'expert_models/new_expert_model_001.pkl'\n",
    "# with open(file, 'rb') as f:\n",
    "#     loaded_expert = pickle.load(f)\n",
    "#     models\n",
    "\n",
    "# print(loaded_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1548a20-d7d8-413f-ae35-fb4a6855235f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "666ba690-ccb4-4290-bcd3-bc14501f3f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tank2OutFlow  Tank2.puddle  Tank3OutFlow  Tank2.level  wt3_valve\n",
      "0       0.167574     -1.407818      0.302357    -0.561930   0.362069\n",
      "1       0.142985     -1.407304      0.207762    -0.584834   0.237220\n",
      "2       0.126681     -1.406831      0.079862    -0.595182   0.137242\n",
      "3       0.144101     -1.406367      0.036569    -0.597515   0.030731\n",
      "4       0.174981     -1.405928     -0.060136    -0.591219  -0.055735\n",
      "5       0.167675     -1.405521     -0.122253    -0.573752  -0.130468\n",
      "6       0.131409     -1.405105     -0.160123    -0.555298  -0.200929\n",
      "7       0.126949     -1.404738     -0.221347    -0.525543  -0.260348\n",
      "8       0.157307     -1.404343     -0.262573    -0.494441  -0.328039\n",
      "9       0.174457     -1.404005     -0.332616    -0.452790  -0.377278\n",
      "10      0.156659     -1.403660     -0.380334    -0.405764  -0.414180\n",
      "11      0.131581     -1.403328     -0.365412    -0.359002  -0.466588\n",
      "12      0.133158     -1.402979     -0.424041    -0.307645  -0.501909\n",
      "13      0.157632     -1.402676     -0.454085    -0.250538  -0.527904\n",
      "14      0.173689     -1.402356     -0.449024    -0.196213  -0.565096\n",
      "15      0.156644     -1.402070     -0.504280    -0.132783  -0.578316\n",
      "16      0.125710     -1.401762     -0.504861    -0.070925  -0.591913\n",
      "17      0.132962     -1.401472     -0.514477    -0.006837  -0.604125\n",
      "18      0.168910     -1.401188     -0.550186     0.060827  -0.610238\n",
      "19      0.173680     -1.400903     -0.547111     0.128567  -0.619728\n"
     ]
    }
   ],
   "source": [
    "pred = my_experts['var_ctrl_stuckat0_perm_reduced'].forecast(input1.values, steps=steps)\n",
    "pred_df = pd.DataFrame(pred, columns=input1.columns)\n",
    "print(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "10c9a5a2-9739-4fe1-9d04-cbef597195fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'new_expert_model_rtov': [0.0021354550210451882, 0.003452036306707881, 1.8336578999520134, 1.3100814206500677, 2.6157282221086757], 'new_expert_model_ugacoqnz': [0.0021354550210451882, 0.003452036306707881, 1.8336578999520134, 1.3100814206500677, 2.6157282221086757], 'var_ctrl_stuckat0_perm_reduced': [0.00036833533223462416, 0.004164067990094714, 0.9762473057958333, 0.4414027873259679, 1.6603695616231695], 'var_ctrl_stuckat1_perm_reduced': [0.00025644039537987785, 0.005448910784125607, 1.6790753615481604, 1.2249391296958394, 2.9688057920471698], 'var_ctrl_valueFlip_perm_reduced': [0.00027591327370826485, 0.004936581415270842, 1.8718764185566505, 1.47729701133969, 2.8946128224560024], 'var_golden_model_reduced': [0.04069243093741203, 0.04468363092548324, 2.3399656712988843, 2.2731034320295183, 2.9755900833086217]}\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in my_experts.items():\n",
    "    predictions = my_experts[model_name].forecast(input1.values, steps=steps)\n",
    "    predictions_df = pd.DataFrame(predictions, columns=input1.columns)\n",
    "    expected = testData.iloc[finish:finish+steps,:].reset_index(drop=True)\n",
    "    RMSE = []\n",
    "    for feature in attr:\n",
    "        RMSE.append(root_mse(predictions_df[feature], expected[feature]))\n",
    "\n",
    "    prediction_error[model_name] = RMSE\n",
    "    \n",
    "print(prediction_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "baf988e1-fd6a-4468-8e55-5c72ef04886a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0021354550210451882, 0.003452036306707881, 1.8336578999520134, 1.3100814206500677, 2.6157282221086757] 1.153011006807702\n",
      "[0.0021354550210451882, 0.003452036306707881, 1.8336578999520134, 1.3100814206500677, 2.6157282221086757] 1.153011006807702\n",
      "[0.00036833533223462416, 0.004164067990094714, 0.9762473057958333, 0.4414027873259679, 1.6603695616231695] 0.61651041161346\n",
      "[0.00025644039537987785, 0.005448910784125607, 1.6790753615481604, 1.2249391296958394, 2.9688057920471698] 1.175705126894135\n",
      "[0.00027591327370826485, 0.004936581415270842, 1.8718764185566505, 1.47729701133969, 2.8946128224560024] 1.2497997494082642\n",
      "[0.04069243093741203, 0.04468363092548324, 2.3399656712988843, 2.2731034320295183, 2.9755900833086217] 1.534807049699984\n"
     ]
    }
   ],
   "source": [
    "for key, value in prediction_error.items():\n",
    "    print(prediction_error[key], np.mean(prediction_error[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dfcb6e3c-0f43-4a6e-a48a-1bbffcf715df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prediction_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "61ad69c9-c5f9-4bf3-bb06-538e89dd1646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_fault(error_dict):\n",
    "    best_val = 100\n",
    "    best_expert = \"\"\n",
    "    for key, value in error_dict.items():\n",
    "        if np.mean(error_dict[key]) < best_val:\n",
    "            best_val = np.mean(error_dict[key])\n",
    "            best_expert = key\n",
    "\n",
    "    \n",
    "    print(f'The best expert is {best_expert}')\n",
    "    if threshold < best_val:\n",
    "        print(f'We need to train additional expert model')\n",
    "    else:\n",
    "        print(f'Congratulations!!! The best expert model is acceptable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d03351d0-4476-4bad-9197-7c4907f9612c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best expert is var_ctrl_stuckat0_perm_reduced\n",
      "We need to train additional expert model\n"
     ]
    }
   ],
   "source": [
    "identify_fault(prediction_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5adc8b8b-a36f-49eb-b879-27e1aeff64ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [124]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mstop\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd363932-5eec-44b7-8e82-971fc202b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_order(data):\n",
    "    model = VAR(data)\n",
    "    selected_order = model.select_order()\n",
    "    order = selected_order.selected_orders['aic']\n",
    "    return order\n",
    "\n",
    "# results = model\n",
    "max_lag = select_order(train)\n",
    "\n",
    "def train_new_expert(data, max_lag):\n",
    "    model = VAR(data)\n",
    "    fitted_expert = model.fit(maxlags=max_lag)\n",
    "    return fitted_expert\n",
    "\n",
    "\n",
    "def generate_random_name(length):\n",
    "    # random_string = ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "    random_string = ''.join(random.choices(string.ascii_letters, k=length))\n",
    "    # return \"expert_models/New_expert_model_\" + random_string + \".pkl\"\n",
    "    return \"new_expert_model_\" + random_string + \".pkl\"\n",
    "\n",
    "\n",
    "# new_expert_model = train_new_expert(train, max_lag)\n",
    "model = VAR(train)\n",
    "new_expert_model = model.fit(maxlags=max_lag)\n",
    "\n",
    "# new_expert_model.k_ar\n",
    "new_expert_model_result = new_expert_model.forecast(y=train.values, steps=steps)\n",
    "print(len(new_expert_model_result))\n",
    "\n",
    "result_forecast = pd.DataFrame(new_expert_model_result, columns=attr)\n",
    "\n",
    "# Save the model\n",
    "expert_name = generate_random_name(8)\n",
    "\n",
    "# with open('expert_models/new_expert_model_001.pkl', 'wb') as f:\n",
    "with open('expert_models/new_expert_model_pp.pkl', 'wb') as f:\n",
    "    pickle.dump(new_expert_model, f)\n",
    "print(\"Model saved!\")\n",
    "\n",
    "# with open('expert_models/' + expert_name, 'wb') as f:\n",
    "#           pickle.dump(new_expert_model, f)\n",
    "# print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb57308-ff9b-4951-a67f-6021f0dcb9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Temporarily stop execution\")\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f57bc-55ff-40f6-95ad-e0154639f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_file = 'test_outputs.csv'\n",
    "# # test_file = 'stuckat1_training_reduced.csv'\n",
    "# # test_file = 'test_series_reduced.csv'\n",
    "# # dff = pd.read_csv(test_file, index_col=0, header=0, parse_dates=True)\n",
    "# dff = pd.read_csv(test_file, index_col=0, header=0)\n",
    "# featt = list(pd.read_csv(test_file, index_col=0, header=0).columns.values)[1:]\n",
    "# plot_series(dff, featt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efffe3cf-9f03-4034-b59d-c51467722871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_dataframe(df):\n",
    "    num_series = len(df.columns)\n",
    "    fig, axes = plt.subplots(num_series, 1, figsize=(10, 5*num_series), sharex=True)\n",
    "    for i, col in enumerate(df.columns):\n",
    "        ax = axes[i] if num_series > 1 else axes\n",
    "        ax.plot(df.index, df[col])\n",
    "        ax.set_title(col)\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c17e77-e2e2-41fe-a6c8-ae7eb99ca1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58762dab-5ebf-4ab4-bca1-1ca97ace62ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
