{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7fb8991-26fd-485f-bdea-db4210cb86da",
   "metadata": {},
   "source": [
    "### Adaptive Fault Detection with VAR Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd88b48-45f7-4061-b2a1-796ccc1b4a7a",
   "metadata": {},
   "source": [
    "##### Import libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d6bf16cb-e4ad-433b-b766-cb8db2ba4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages and libraries\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "from statsmodels.tsa.api import VAR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignoe harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the plot size default\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (12, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a927d1-92a1-4fad-a170-98679fb7c154",
   "metadata": {},
   "source": [
    "### Defining methods or functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b3720217-1183-4f5b-8fdd-2d324345f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting multiple series\n",
    "def plot_multiple_series(actual, pred, attr):\n",
    "    for i in range(len(attr)):\n",
    "        title = \"Prediction of {}\".format(attr[i])\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Timestep\")\n",
    "        plt.ylabel(\"Values\")\n",
    "        plt.plot(actual.iloc[:,i], label=\"actual\")\n",
    "        plt.plot(pred.iloc[:,i], label=\"forecast\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Root mean squared error\n",
    "def root_mse(x, y):\n",
    "    if len(x) != len(y):\n",
    "        return \"Error: The two arguments must have the same length\"\n",
    "    mse = np.square(np.subtract(x, y)).mean()\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "# Plotting series\n",
    "def plot_series(series, attr):\n",
    "    for i in range(len(attr)):\n",
    "        title = \"Plot of \"+str(attr[i])\n",
    "        actual = series.iloc[:,i]\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Timestep\")\n",
    "        plt.ylabel(attr[i])\n",
    "        plt.plot(actual)\n",
    "        plt.show()\n",
    "\n",
    "# Normalisation of time series\n",
    "def normalise_timeseries(data):\n",
    "    # Calculate the mean and standard deviation for each feature\n",
    "    means = np.mean(data, axis=0)\n",
    "    stds = np.std(data, axis=0)\n",
    "    \n",
    "    # Normalise each feature using standard deviation\n",
    "    normalised_data = (data - means) / stds\n",
    "    return pd.DataFrame(normalised_data)\n",
    "\n",
    "\n",
    "# Denomalisation of time series\n",
    "def denormalise_timeseries(data, means, stds):\n",
    "    denormalised_data = (data * stds) + means\n",
    "    return pd.DataFrame(denormalised_data)\n",
    "\n",
    "\n",
    "# Augmented Dickey-Fuller Test\n",
    "def adf_test(series, title=''):\n",
    "    '''\n",
    "    Hypothesis Test for Stationarity\n",
    "    Pass in a time series and an optional title, return an ADF report\n",
    "    '''\n",
    "    print(f'Augmented Dickey-Fuller Test: {title}')\n",
    "    result = adfuller(series.dropna(),autolag='AIC')\n",
    "    labels = ['ADF test statistics','p-value','#lags','#observations'] # use help(adfuller) to understand why these labels are chosen\n",
    "    \n",
    "    outcome = pd.Series(result[0:4],index=labels)\n",
    "    \n",
    "    for key,val in result[4].items():\n",
    "        outcome[f'critical value ({key})'] = val\n",
    "        \n",
    "    print(outcome.to_string()) # this will not print the line 'dtype:float64'\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print('Strong evidence against the null hypothesis') # Ho is Data is not stationary, check help(adfuller)\n",
    "        print('Reject the null hypothesis')\n",
    "        print('Data is Stationary')\n",
    "    else:\n",
    "        print('Weak evidence against the Null hypothesis')\n",
    "        print('Fail to reject the null hypothesis')\n",
    "        print('Data has a unit root and is non stationary')\n",
    "\n",
    "\n",
    "# Loading expert models in a dictionary and count the number of expert models\n",
    "def load_expert_models(expert_path):\n",
    "    files = os.listdir(expert_path)\n",
    "    pickle_files = [file for file in files if file.endswith('.pkl')]\n",
    "    models = {}\n",
    "\n",
    "    for file in pickle_files:\n",
    "        with open(file, 'rb') as f:\n",
    "            loaded_expert = pickle.load(f)\n",
    "            models[file.split('.')[0]] = loaded_expert\n",
    "            # models[file.split('.')[0]] = pickle.load(f)\n",
    "\n",
    "    # return models, len(models)\n",
    "    return models\n",
    "\n",
    "\n",
    "# Count the number of expert models in the repository\n",
    "# def count_expert_models():\n",
    "\n",
    "def file_names_string(file_path):\n",
    "    files = os.listdir(file_path)\n",
    "    for file_name in files:\n",
    "        if not isinstance(file_name, str):\n",
    "            return False\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "906ba73d-7a64-47b5-83c0-885b814b55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning variables\n",
    "# file = 'test_series_reduced.csv'\n",
    "# file = 'stuckat1_training_reduced_new.csv'\n",
    "file = 'valueflip_training_reduced_new.csv'\n",
    "# file = 'stuckat1_training_reduced.csv'\n",
    "experts_path = 'expert_models'\n",
    "df_raw = read_csv(file, header=0, index_col=0)\n",
    "attr = list(pd.read_csv(file).columns.values)[1:]\n",
    "series = df_raw.iloc[:40000,:]\n",
    "# plot_series(series, attr)\n",
    "nobs = 3000\n",
    "# steps = 15\n",
    "steps = 20\n",
    "begin = 2000\n",
    "finish = 2200\n",
    "normalised_data = normalise_timeseries(df_raw)\n",
    "testData = normalised_data.copy()\n",
    "train = testData.iloc[:-nobs]\n",
    "test = testData.iloc[-nobs:]\n",
    "# len(train), len(test)\n",
    "input1 = testData.iloc[begin:finish,:]\n",
    "# plot_series(input1, attr)\n",
    "prediction_error = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8ec906ac-c777-460e-bae0-96c6883702b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold prediction error value\n",
    "threshold = 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "44cb1b04-0f56-47e9-abb8-84a1ba5ee808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "checker = file_names_string(expert_path)\n",
    "print(checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8dd338af-bf6b-4075-9492-924feb7a1890",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'new_expert_model_001.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [198]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the expert models\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m my_experts \u001b[38;5;241m=\u001b[39m \u001b[43mload_expert_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperts_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# print(my_experts)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(my_experts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar_ctrl_stuckat0_perm_reduced\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Input \u001b[1;32mIn [194]\u001b[0m, in \u001b[0;36mload_expert_models\u001b[1;34m(expert_path)\u001b[0m\n\u001b[0;32m     80\u001b[0m models \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m pickle_files:\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     84\u001b[0m         loaded_expert \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     85\u001b[0m         models[file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m loaded_expert\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'new_expert_model_001.pkl'"
     ]
    }
   ],
   "source": [
    "# Load the expert models\n",
    "my_experts = load_expert_models(experts_path)\n",
    "# print(my_experts)\n",
    "print(my_experts['var_ctrl_stuckat0_perm_reduced'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1548a20-d7d8-413f-ae35-fb4a6855235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myfile = \"expert_models/new_expert_model_r8UakMv4.pkl\"\n",
    "myfile = \"expert_models/var_golden_model_reduced.pkl\"\n",
    "with open(myfile, 'rb') as f:\n",
    "    test_file = pickle.load(f)\n",
    "    print(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ba690-ccb4-4290-bcd3-bc14501f3f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = my_experts['var_ctrl_stuckat0_perm_reduced'].forecast(input1.values, steps=steps)\n",
    "pred_df = pd.DataFrame(pred, columns=input1.columns)\n",
    "print(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c9a5a2-9739-4fe1-9d04-cbef597195fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in my_experts.items():\n",
    "    predictions = my_experts[model_name].forecast(input1.values, steps=steps)\n",
    "    predictions_df = pd.DataFrame(predictions, columns=input1.columns)\n",
    "    expected = testData.iloc[finish:finish+steps,:].reset_index(drop=True)\n",
    "    RMSE = []\n",
    "    for feature in attr:\n",
    "        RMSE.append(root_mse(predictions_df[feature], expected[feature]))\n",
    "\n",
    "    prediction_error[model_name] = RMSE\n",
    "    \n",
    "print(prediction_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf988e1-fd6a-4468-8e55-5c72ef04886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in prediction_error.items():\n",
    "    print(prediction_error[key], np.mean(prediction_error[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcb6e3c-0f43-4a6e-a48a-1bbffcf715df",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(prediction_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad69c9-c5f9-4bf3-bb06-538e89dd1646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_fault(error_dict):\n",
    "    best_val = 100\n",
    "    best_expert = \"\"\n",
    "    for key, value in error_dict.items():\n",
    "        if np.mean(error_dict[key]) < best_val:\n",
    "            best_val = np.mean(error_dict[key])\n",
    "            best_expert = key\n",
    "\n",
    "    \n",
    "    print(f'The best expert is {best_expert}')\n",
    "    if threshold < best_val:\n",
    "        print(f'We need to train additional expert model')\n",
    "    else:\n",
    "        print(f'Congratulations!!! The best expert model is acceptable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03351d0-4476-4bad-9197-7c4907f9612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_fault(prediction_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc8b8b-a36f-49eb-b879-27e1aeff64ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd363932-5eec-44b7-8e82-971fc202b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_order(data):\n",
    "    model = VAR(data)\n",
    "    selected_order = model.select_order()\n",
    "    order = selected_order.selected_orders['aic']\n",
    "    return order\n",
    "\n",
    "# results = model\n",
    "max_lag = select_order(train)\n",
    "\n",
    "def train_new_expert(data, max_lag):\n",
    "    model = VAR(data)\n",
    "    fitted_expert = model.fit(maxlags=max_lag)\n",
    "    return fitted_expert\n",
    "\n",
    "\n",
    "def generate_random_name(length):\n",
    "    random_string = ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "    # return \"expert_models/New_expert_model_\" + random_string + \".pkl\"\n",
    "    return \"new_expert_model_\" + random_string + \".pkl\"\n",
    "\n",
    "\n",
    "# new_expert_model = train_new_expert(train, max_lag)\n",
    "model = VAR(train)\n",
    "new_expert_model = model.fit(maxlags=max_lag)\n",
    "\n",
    "# new_expert_model.k_ar\n",
    "new_expert_model_result = new_expert_model.forecast(y=train.values, steps=steps)\n",
    "print(len(new_expert_model_result))\n",
    "\n",
    "result_forecast = pd.DataFrame(new_expert_model_result, columns=attr)\n",
    "\n",
    "# Save the model\n",
    "expert_name = generate_random_name(8)\n",
    "\n",
    "# with open('expert_models/new_expert_model_001.pkl', 'wb') as f:\n",
    "with open('expert_models/new_expert_model_001.pkl', 'wb') as f:\n",
    "    pickle.dump(new_expert_model, f)\n",
    "print(\"Model saved!\")\n",
    "\n",
    "# with open('expert_models/' + expert_name, 'wb') as f:\n",
    "#           pickle.dump(new_expert_model, f)\n",
    "# print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb57308-ff9b-4951-a67f-6021f0dcb9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Temporarily stop execution\")\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f57bc-55ff-40f6-95ad-e0154639f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_file = 'test_outputs.csv'\n",
    "# # test_file = 'stuckat1_training_reduced.csv'\n",
    "# # test_file = 'test_series_reduced.csv'\n",
    "# # dff = pd.read_csv(test_file, index_col=0, header=0, parse_dates=True)\n",
    "# dff = pd.read_csv(test_file, index_col=0, header=0)\n",
    "# featt = list(pd.read_csv(test_file, index_col=0, header=0).columns.values)[1:]\n",
    "# plot_series(dff, featt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efffe3cf-9f03-4034-b59d-c51467722871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_dataframe(df):\n",
    "    num_series = len(df.columns)\n",
    "    fig, axes = plt.subplots(num_series, 1, figsize=(10, 5*num_series), sharex=True)\n",
    "    for i, col in enumerate(df.columns):\n",
    "        ax = axes[i] if num_series > 1 else axes\n",
    "        ax.plot(df.index, df[col])\n",
    "        ax.set_title(col)\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c17e77-e2e2-41fe-a6c8-ae7eb99ca1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58762dab-5ebf-4ab4-bca1-1ca97ace62ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
