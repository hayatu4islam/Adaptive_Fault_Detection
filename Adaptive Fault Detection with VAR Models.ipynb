{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7fb8991-26fd-485f-bdea-db4210cb86da",
   "metadata": {},
   "source": [
    "### Adaptive Fault Detection with VAR Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd88b48-45f7-4061-b2a1-796ccc1b4a7a",
   "metadata": {},
   "source": [
    "##### Import libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6bf16cb-e4ad-433b-b766-cb8db2ba4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages and libraries\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from statsmodels.tsa.api import VAR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignoe harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the plot size default\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (12, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a927d1-92a1-4fad-a170-98679fb7c154",
   "metadata": {},
   "source": [
    "### Defining methods or functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3720217-1183-4f5b-8fdd-2d324345f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting multiple series\n",
    "def plot_multiple_series(actual, pred, attr):\n",
    "    for i in range(len(attr)):\n",
    "        title = \"Prediction of {}\".format(attr[i])\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Timestep\")\n",
    "        plt.ylabel(\"Values\")\n",
    "        plt.plot(actual.iloc[:,i], label=\"actual\")\n",
    "        plt.plot(pred.iloc[:,i], label=\"forecast\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Root mean squared error\n",
    "def root_mse(x, y):\n",
    "    if len(x) != len(y):\n",
    "        return \"Error: The two arguments must have the same length\"\n",
    "    mse = np.square(np.subtract(x, y)).mean()\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "# Plotting series\n",
    "def plot_series(series, attr):\n",
    "    for i in range(len(attr)):\n",
    "        title = \"Plot of \"+str(attr[i])\n",
    "        actual = series.iloc[:,i]\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Timestep\")\n",
    "        plt.ylabel(attr[i])\n",
    "        plt.plot(actual)\n",
    "        plt.show()\n",
    "\n",
    "# Normalisation of time series\n",
    "def normalise_timeseries(data):\n",
    "    # Calculate the mean and standard deviation for each feature\n",
    "    means = np.mean(data, axis=0)\n",
    "    stds = np.std(data, axis=0)\n",
    "    \n",
    "    # Normalise each feature using standard deviation\n",
    "    normalised_data = (data - means) / stds\n",
    "    return pd.DataFrame(normalised_data)\n",
    "\n",
    "\n",
    "# Denomalisation of time series\n",
    "def denormalise_timeseries(data, means, stds):\n",
    "    denormalised_data = (data * stds) + means\n",
    "    return pd.DataFrame(denormalised_data)\n",
    "\n",
    "\n",
    "# Augmented Dickey-Fuller Test\n",
    "def adf_test(series, title=''):\n",
    "    '''\n",
    "    Hypothesis Test for Stationarity\n",
    "    Pass in a time series and an optional title, return an ADF report\n",
    "    '''\n",
    "    print(f'Augmented Dickey-Fuller Test: {title}')\n",
    "    result = adfuller(series.dropna(),autolag='AIC')\n",
    "    labels = ['ADF test statistics','p-value','#lags','#observations'] # use help(adfuller) to understand why these labels are chosen\n",
    "    \n",
    "    outcome = pd.Series(result[0:4],index=labels)\n",
    "    \n",
    "    for key,val in result[4].items():\n",
    "        outcome[f'critical value ({key})'] = val\n",
    "        \n",
    "    print(outcome.to_string()) # this will not print the line 'dtype:float64'\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print('Strong evidence against the null hypothesis') # Ho is Data is not stationary, check help(adfuller)\n",
    "        print('Reject the null hypothesis')\n",
    "        print('Data is Stationary')\n",
    "    else:\n",
    "        print('Weak evidence against the Null hypothesis')\n",
    "        print('Fail to reject the null hypothesis')\n",
    "        print('Data has a unit root and is non stationary')\n",
    "\n",
    "\n",
    "# Loading expert models in a dictionary\n",
    "def load_expert_models(expert_path):\n",
    "    files = os.listdir(expert_path)\n",
    "    pickle_files = [file for file in files if file.endswith('.pkl')]\n",
    "    models = {}\n",
    "\n",
    "    for file in pickle_files:\n",
    "        with open(file, 'rb') as f:\n",
    "            models[file.split('.')[0]] = pickle.load(f)\n",
    "\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "906ba73d-7a64-47b5-83c0-885b814b55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning variables\n",
    "file = 'test_series_reduced.csv'\n",
    "expert_path = 'expert_models'\n",
    "df_raw = read_csv(file, header=0, index_col=0)\n",
    "attr = list(pd.read_csv(file).columns.values)[1:]\n",
    "series = df_raw.iloc[:40000,:]\n",
    "# plot_series(series, attr)\n",
    "nobs = 3000\n",
    "steps = 15\n",
    "begin = 2000\n",
    "finish = 2200\n",
    "normalised_data = normalise_timeseries(df_raw)\n",
    "testData = normalised_data.copy()\n",
    "train = testData.iloc[:-nobs]\n",
    "test = testData.iloc[-nobs:]\n",
    "# len(train), len(test)\n",
    "input1 = testData.iloc[begin:finish,:]\n",
    "# plot_series(input1, attr)\n",
    "prediction_error = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ec906ac-c777-460e-bae0-96c6883702b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold prediction error value\n",
    "threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8dd338af-bf6b-4075-9492-924feb7a1890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<statsmodels.tsa.vector_ar.var_model.VARResultsWrapper object at 0x0000021B8BFA0190>\n"
     ]
    }
   ],
   "source": [
    "# Load the expert models\n",
    "my_experts = load_expert_models(expert_path)\n",
    "# print(my_experts)\n",
    "print(my_experts['var_ctrl_stuckat0_perm_reduced'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "666ba690-ccb4-4290-bcd3-bc14501f3f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tank2OutFlow  Tank2.puddle  Tank3OutFlow  Tank2.level  wt3_valve\n",
      "0       0.167070     -1.384515     -0.463802    -0.241040  -0.905951\n",
      "1       0.141919     -1.383891     -0.721586    -0.194511  -0.866651\n",
      "2       0.125196     -1.383256     -0.843049    -0.098893  -0.833221\n",
      "3       0.142421     -1.382417     -0.884744    -0.013308  -0.802514\n",
      "4       0.172772     -1.381530     -0.949448     0.097097  -0.757113\n",
      "5       0.164618     -1.380516     -0.942693     0.197030  -0.733433\n",
      "6       0.127007     -1.379444     -0.979027     0.312421  -0.678512\n",
      "7       0.121581     -1.378168     -0.919090     0.415575  -0.645130\n",
      "8       0.151352     -1.376834     -0.915884     0.523388  -0.629673\n",
      "9       0.167571     -1.375457     -0.884227     0.637498  -0.942391\n",
      "10      0.147800     -1.374225     -1.295399     0.790190  -1.088435\n",
      "11      0.121310     -1.373215     -1.472037     0.976467  -1.175066\n",
      "12      0.122841     -1.372202     -1.544801     1.167983  -1.203015\n",
      "13      0.147034     -1.371339     -1.555103     1.366777  -1.221377\n",
      "14      0.161123     -1.370531     -1.514278     1.559345  -1.182050\n"
     ]
    }
   ],
   "source": [
    "pred = my_experts['var_ctrl_stuckat0_perm_reduced'].forecast(input1.values, steps=steps)\n",
    "pred_df = pd.DataFrame(pred, columns=input1.columns)\n",
    "print(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10c9a5a2-9739-4fe1-9d04-cbef597195fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_ctrl_stuckat0_perm_reduced': [0.007102182269043727, 0.008426043640523146, 0.734199579539484, 0.9042479663906864, 0.29496410176651794], 'var_ctrl_stuckat1_perm_reduced': [0.006846122248261372, 0.009497363321898862, 0.16098232318874026, 0.29123533230704285, 0.1680542097506921], 'var_ctrl_valueFlip_perm_reduced': [0.005517063708583547, 0.006751388299625716, 0.8405323572154951, 1.2433226706807265, 0.7744986923149207], 'var_golden_model_reduced': [0.012114486610909534, 0.006626271854935035, 0.3489223646683037, 0.6767479842540826, 0.2109692138410525]}\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in my_experts.items():\n",
    "    predictions = my_experts[model_name].forecast(input1.values, steps=steps)\n",
    "    predictions_df = pd.DataFrame(predictions, columns=input1.columns)\n",
    "    expected = testData.iloc[finish:finish+steps,:].reset_index(drop=True)\n",
    "    RMSE = []\n",
    "    for feature in attr:\n",
    "        RMSE.append(root_mse(predictions_df[feature], expected[feature]))\n",
    "\n",
    "    prediction_error[model_name] = RMSE\n",
    "    \n",
    "print(prediction_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf988e1-fd6a-4468-8e55-5c72ef04886a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
