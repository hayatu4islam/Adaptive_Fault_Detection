{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d731aa-9175-4b90-8d04-8c727160b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# define the plot size default\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (12,5)\n",
    "\n",
    "# load specific forecasting tools\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tools.eval_measures import mse,rmse\n",
    "\n",
    "# Ignore harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pickle\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc02ca5f-0e1d-417b-928d-985979e90378",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Inferred frequency None from passed values does not conform to passed frequency L",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:1913\u001b[0m, in \u001b[0;36mTimelikeOps._validate_frequency\u001b[1;34m(cls, index, freq, **kwargs)\u001b[0m\n\u001b[0;32m   1912\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(index\u001b[38;5;241m.\u001b[39masi8, on_freq\u001b[38;5;241m.\u001b[39masi8):\n\u001b[1;32m-> 1913\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n\u001b[0;32m   1914\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mValueError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphy_cps.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m df_raw \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_name, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, parse_dates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m df_raw\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mfreq \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Augmented Dickey-Fuller Test\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madf_test\u001b[39m(series, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\datetimelike.py:100\u001b[0m, in \u001b[0;36mDatetimeIndexOpsMixin.freq\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;129m@freq\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfreq\u001b[39m(\u001b[38;5;28mself\u001b[39m, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# error: Property \"freq\" defined in \"PeriodArray\" is read-only  [misc]\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mfreq \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:1879\u001b[0m, in \u001b[0;36mTimelikeOps.freq\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   1877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1878\u001b[0m     value \u001b[38;5;241m=\u001b[39m to_offset(value)\n\u001b[1;32m-> 1879\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_frequency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1881\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1882\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set freq with ndim > 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:1924\u001b[0m, in \u001b[0;36mTimelikeOps._validate_frequency\u001b[1;34m(cls, index, freq, **kwargs)\u001b[0m\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m   1919\u001b[0m \u001b[38;5;66;03m# GH#11587 the main way this is reached is if the `np.array_equal`\u001b[39;00m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m#  check above is False.  This can also be reached if index[0]\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m#  is `NaT`, in which case the call to `cls._generate_range` will\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m#  raise a ValueError, which we re-raise with a more targeted\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m#  message.\u001b[39;00m\n\u001b[1;32m-> 1924\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1925\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferred frequency \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minferred\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from passed values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1926\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not conform to passed frequency \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfreq\u001b[38;5;241m.\u001b[39mfreqstr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1927\u001b[0m ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Inferred frequency None from passed values does not conform to passed frequency L"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "file_name = \"phy_cps.csv\"\n",
    "df_raw = pd.read_csv(file_name, index_col=0, header=0, parse_dates=True)\n",
    "df_raw.index.freq = 'ms'\n",
    "\n",
    "# Augmented Dickey-Fuller Test\n",
    "def adf_test(series, title=''):\n",
    "    '''\n",
    "    Hypothesis Test for Stationarity\n",
    "    Pass in a time series and an optional title, return an ADF report\n",
    "    '''\n",
    "    print(f'Augmented Dickey-Fuller Test: {title}')\n",
    "    result = adfuller(series.dropna(),autolag='AIC')\n",
    "    labels = ['ADF test statistics','p-value','#lags','#observations'] # use help(adfuller) to understand why these labels are chosen\n",
    "    \n",
    "    outcome = pd.Series(result[0:4],index=labels)\n",
    "    \n",
    "    for key,val in result[4].items():\n",
    "        outcome[f'critical value ({key})'] = val\n",
    "        \n",
    "    print(outcome.to_string()) # this will not print the line 'dtype:float64'\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print('Strong evidence against the null hypothesis') # Ho is Data is not stationary, check help(adfuller)\n",
    "        print('Reject the null hypothesis')\n",
    "        print('Data is Stationary')\n",
    "    else:\n",
    "        print('Weak evidence against the Null hypothesis')\n",
    "        print('Fail to reject the null hypothesis')\n",
    "        print('Data has a unit root and is non stationary')\n",
    "\n",
    "\n",
    "def normalise_timeseries(data):\n",
    "    # Calculate the mean and standard deviation for each feature\n",
    "    means = np.mean(data, axis=0)\n",
    "    stds = np.std(data, axis=0)\n",
    "    \n",
    "    # Normalise each feature using standard deviation\n",
    "    normalised_data = (data - means) / stds\n",
    "#     return pd.DataFrame(normalised_data), means, stds\n",
    "    return pd.DataFrame(normalised_data), means, stds\n",
    "\n",
    "\n",
    "def denormalise_timeseries(data, means, stds):\n",
    "    denormalised_data = (data * stds) + means\n",
    "    return pd.DataFrame(denormalised_data)\n",
    "\n",
    "\n",
    "normalised_data, means, stds = normalise_timeseries(df_raw)\n",
    "\n",
    "### METHOD ONE: USE %STORE MAGIC COMMAND\n",
    "stored_norm_vars = pd.concat([means, stds], axis=1) # Stored Normalisation variables\n",
    "%store stored_norm_vars\n",
    "\n",
    "### METHOD TWO: SAVE AS A FILE\n",
    "file_path = 'norm_var_reduced.csv'\n",
    "norm_vars = pd.concat([means, stds], axis=1)\n",
    "norm_vars.to_csv(file_path)\n",
    "\n",
    "# Train Test Split\n",
    "nobs = 3000\n",
    "# train = df[:-nobs]\n",
    "train = df.iloc[:-nobs]\n",
    "test = df.iloc[-nobs:]\n",
    "len(train), len(test)\n",
    "\n",
    "# from statsmodels.tsa.vector_ar.var_model import VAROrderSelection\n",
    "# Perform order selection using auto-arima\n",
    "model = VAR(train)\n",
    "# Select the best order based on a specific criterion (e.g. AIC, BIC)\n",
    "selected_order = model.select_order()\n",
    "# Get the selected order (lag length)\n",
    "order = selected_order.selected_orders['aic']\n",
    "min_aic_index = order\n",
    "print('Order {0} has the least AIC value. Let us select p = {0} in the modelling'.format(min_aic_index))\n",
    "\n",
    "results = model.fit(min_aic_index)\n",
    "\n",
    "# For predictions, VAR model uses .forecast() instead of predictions.\n",
    "lag_order = results.k_ar\n",
    "\n",
    "steps = 20\n",
    "# z = results.forecast(y=train.values[-lag_order:], steps = 20)\n",
    "z = results.forecast(y=train.values, steps=steps)\n",
    "\n",
    "attr = list(pd.read_csv(file_name).columns.values)[1:]\n",
    "df_forecast = pd.DataFrame(z, columns=attr)\n",
    "\n",
    "attr = list(pd.read_csv(file_name).columns.values)[1:]\n",
    "# attr = ['Tank1WaterLevel', 'Tank2WaterLevel', 'Tank1InFlow', 'Tank2OutFlow', 'wt3_valve', 'Tank3OutFlow', 'Tank2.level']\n",
    "input_length = 20\n",
    "for i in range(len(attr)):\n",
    "    title = \"Prediction of {}\".format(attr[i])\n",
    "    actual_index = pd.Index(list(range(1,input_length+1)))\n",
    "#     actual = train.iloc[-lag_order:,:] # CORRECT BEFORE EDITING\n",
    "    actual = train.iloc[-input_length:,:]\n",
    "    \n",
    "#     index = pd.Index(list(range(lag_order, lag_order + steps))) # CORRECT BEFORE EDITING\n",
    "    index = pd.Index(list(range(input_length+1, input_length + steps +1)))\n",
    "    actual = actual.set_index(actual_index)\n",
    "    pred = df_forecast.set_index(index)\n",
    "    actual_test = test.iloc[:input_length,:].set_index(index)\n",
    "    # draw a vertical line at x=20\n",
    "#     plt.axvline(x=lag_order, ls='--', color='red') # CORRECT BEFORE EDITING\n",
    "    plt.axvline(x=input_length, ls='--', color='red')\n",
    "#     pred = df_forecast\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Timestep\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.plot(actual.iloc[:,i])\n",
    "    plt.plot(pred.iloc[:,i], label=\"forecast\")\n",
    "    plt.plot(actual_test.iloc[:,i], label=\"actual\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "RMSE = []\n",
    "for feat in attr:\n",
    "    RMSE.append(rmse(pred[feat], actual_test[feat]))\n",
    "\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af90ee54-528c-4fa1-a2c7-57bb056ebae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a93e484-ce76-4ea1-a7eb-29e599555abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
