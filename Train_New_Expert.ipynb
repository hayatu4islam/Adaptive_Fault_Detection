{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "308c100f-6e3c-4c65-8b6b-afef423f7592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages and libraries\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "from statsmodels.tsa.api import VAR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignoe harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the plot size default\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (12, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0549ee29-a54c-47ad-b04a-eb4f9b76385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data = 'new_data.csv'\n",
    "new_data = 'valueflip_training_reduced_new.csv'\n",
    "df_raw = pd.read_csv(new_data, index_col=0, header=0, parse_dates=True)\n",
    "df_raw.index.freq = 'ms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd6a2d2f-0b1a-4904-92ec-50356668e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_timeseries(data):\n",
    "    # Calculate the mean and standard deviation for each feature\n",
    "    means = np.mean(data, axis=0)\n",
    "    stds = np.std(data, axis=0)\n",
    "    \n",
    "    # Normalise each feature using standard deviation\n",
    "    normalised_data = (data - means) / stds\n",
    "#     return pd.DataFrame(normalised_data), means, stds\n",
    "    return pd.DataFrame(normalised_data), means, stds\n",
    "\n",
    "\n",
    "def denormalise_timeseries(data, means, stds):\n",
    "    denormalised_data = (data * stds) + means\n",
    "    return pd.DataFrame(denormalised_data)\n",
    "\n",
    "def generate_random_name(length):\n",
    "    # random_string = ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "    random_string = ''.join(random.choices(string.ascii_letters, k=length))\n",
    "    # return \"expert_models/New_expert_model_\" + random_string + \".pkl\"\n",
    "    # return str(\"new_expert_model_\" + random_string.lower() + \".pkl\")\n",
    "    return str(\"new_expert_model.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "normalised_data, means, stds = normalise_timeseries(df_raw)\n",
    "df = normalised_data.copy()\n",
    "\n",
    "#  MAY BE YOU NEED TO REMOVE THE LINES BELOW\n",
    "# Train Test Split\n",
    "nobs = 3000\n",
    "# train = df[:-nobs]\n",
    "train = df.iloc[:-nobs]\n",
    "test = df.iloc[-nobs:]\n",
    "len(train), len(test)\n",
    "# print(len(train))\n",
    "# print(len(df))\n",
    "train = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "267d7a44-d1b5-487f-b9e9-572e618d5c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "# Perform order selection using auto-arima\n",
    "model = VAR(train)\n",
    "# Select the best order based on a specific criterion (e.g. AIC, BIC)\n",
    "selected_order = model.select_order()\n",
    "# Get the selected order (lag length)\n",
    "order = selected_order.selected_orders['aic']\n",
    "min_aic_index = order.copy()\n",
    "results = model.fit(min_aic_index)\n",
    "\n",
    "steps = 20\n",
    "# z = results.forecast(y=train.values[-lag_order:], steps = 20)\n",
    "z = results.forecast(y=train.values, steps=steps)\n",
    "\n",
    "attr = list(pd.read_csv(new_data).columns.values)[1:]\n",
    "df_forecast = pd.DataFrame(z, columns=attr)\n",
    "\n",
    "# Save the expert model\n",
    "expert_name = generate_random_name(8)\n",
    "\n",
    "data = {'key': 'value'}\n",
    "\n",
    "# Specify the subdirectory name\n",
    "subdirectory = 'expert_models'\n",
    "\n",
    "# Ensure the subdirectory exists, create it if necessary\n",
    "os.makedirs(subdirectory, exist_ok=True)\n",
    "\n",
    "# Construct the file path within the subdirectory\n",
    "file_path = os.path.join(subdirectory, 'var_golden_models_reduced.pkl')\n",
    "\n",
    "# Write data to a pickle file in the subdirectory\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "\n",
    "\n",
    "# # with open('expert_models/new_expert_model_001.pkl', 'wb') as f:\n",
    "# with open('expert_models/var_golden_models_reduced.pkl', 'wb') as f:\n",
    "#     pickle.dump(results, f)\n",
    "\n",
    "f.close()\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc088a22-d6bb-43db-b973-1f339044e101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
