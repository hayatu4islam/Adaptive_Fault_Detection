{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7fb8991-26fd-485f-bdea-db4210cb86da",
   "metadata": {},
   "source": [
    "### Adaptive Fault Detection with VAR Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd88b48-45f7-4061-b2a1-796ccc1b4a7a",
   "metadata": {},
   "source": [
    "##### Import libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6bf16cb-e4ad-433b-b766-cb8db2ba4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages and libraries\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from statsmodels.tsa.api import VAR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignoe harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the plot size default\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (12, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a927d1-92a1-4fad-a170-98679fb7c154",
   "metadata": {},
   "source": [
    "### Defining methods or functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3720217-1183-4f5b-8fdd-2d324345f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting multiple series\n",
    "def plot_multiple_series(actual, pred, attr):\n",
    "    for i in range(len(attr)):\n",
    "        title = \"Prediction of {}\".format(attr[i])\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Timestep\")\n",
    "        plt.ylabel(\"Values\")\n",
    "        plt.plot(actual.iloc[:,i], label=\"actual\")\n",
    "        plt.plot(pred.iloc[:,i], label=\"forecast\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Root mean squared error\n",
    "def root_mse(x, y):\n",
    "    if len(x) != len(y):\n",
    "        return \"Error: The two arguments must have the same length\"\n",
    "    mse = np.square(np.subtract(x, y)).mean()\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "# Plotting series\n",
    "def plot_series(series, attr):\n",
    "    for i in range(len(attr)):\n",
    "        title = \"Plot of \"+str(attr[i])\n",
    "        actual = series.iloc[:,i]\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Timestep\")\n",
    "        plt.ylabel(attr[i])\n",
    "        plt.plot(actual)\n",
    "        plt.show()\n",
    "\n",
    "# Normalisation of time series\n",
    "def normalise_timeseries(data):\n",
    "    # Calculate the mean and standard deviation for each feature\n",
    "    means = np.mean(data, axis=0)\n",
    "    stds = np.std(data, axis=0)\n",
    "    \n",
    "    # Normalise each feature using standard deviation\n",
    "    normalised_data = (data - means) / stds\n",
    "    return pd.DataFrame(normalised_data)\n",
    "\n",
    "\n",
    "# Denomalisation of time series\n",
    "def denormalise_timeseries(data, means, stds):\n",
    "    denormalised_data = (data * stds) + means\n",
    "    return pd.DataFrame(denormalised_data)\n",
    "\n",
    "\n",
    "# Augmented Dickey-Fuller Test\n",
    "def adf_test(series, title=''):\n",
    "    '''\n",
    "    Hypothesis Test for Stationarity\n",
    "    Pass in a time series and an optional title, return an ADF report\n",
    "    '''\n",
    "    print(f'Augmented Dickey-Fuller Test: {title}')\n",
    "    result = adfuller(series.dropna(),autolag='AIC')\n",
    "    labels = ['ADF test statistics','p-value','#lags','#observations'] # use help(adfuller) to understand why these labels are chosen\n",
    "    \n",
    "    outcome = pd.Series(result[0:4],index=labels)\n",
    "    \n",
    "    for key,val in result[4].items():\n",
    "        outcome[f'critical value ({key})'] = val\n",
    "        \n",
    "    print(outcome.to_string()) # this will not print the line 'dtype:float64'\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print('Strong evidence against the null hypothesis') # Ho is Data is not stationary, check help(adfuller)\n",
    "        print('Reject the null hypothesis')\n",
    "        print('Data is Stationary')\n",
    "    else:\n",
    "        print('Weak evidence against the Null hypothesis')\n",
    "        print('Fail to reject the null hypothesis')\n",
    "        print('Data has a unit root and is non stationary')\n",
    "\n",
    "\n",
    "# Loading expert models in a dictionary\n",
    "def load_expert_models(expert_path):\n",
    "    files = os.listdir(expert_path)\n",
    "    pickle_files = [file for file in files if file.endswith('.pkl')]\n",
    "    models = {}\n",
    "\n",
    "    for file in pickle_files:\n",
    "        with open(file, 'rb') as f:\n",
    "            models[file.split('.')[0]] = pickle.load(f)\n",
    "\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906ba73d-7a64-47b5-83c0-885b814b55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning variables\n",
    "file = 'test_series_reduced.csv'\n",
    "expert_path = 'expert_models'\n",
    "df_raw = read_csv(file, header=0, index_col=0)\n",
    "attr = list(pd.read_csv(file).columns.values)[1:]\n",
    "series = df_raw.iloc[:40000,:]\n",
    "plot_series(series, attr)\n",
    "nobs = 3000\n",
    "steps = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dd338af-bf6b-4075-9492-924feb7a1890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_ctrl_stuckat0_perm_reduced': <statsmodels.tsa.vector_ar.var_model.VARResultsWrapper object at 0x0000021B87512260>, 'var_ctrl_stuckat1_perm_reduced': <statsmodels.tsa.vector_ar.var_model.VARResultsWrapper object at 0x0000021B87644760>, 'var_ctrl_valueFlip_perm_reduced': <statsmodels.tsa.vector_ar.var_model.VARResultsWrapper object at 0x0000021B876D2E60>, 'var_golden_model_reduced': <statsmodels.tsa.vector_ar.var_model.VARResultsWrapper object at 0x0000021B8CDC0C10>}\n"
     ]
    }
   ],
   "source": [
    "my_experts = load_expert_models(expert_path)\n",
    "print(my_experts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10c9a5a2-9739-4fe1-9d04-cbef597195fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17001, 3000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalised_data = normalise_timeseries(df_raw)\n",
    "testData = normalised_data.copy()\n",
    "train = testData.iloc[:-nobs]\n",
    "test = testData.iloc[-nobs:]\n",
    "len(train), len(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
